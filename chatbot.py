# -*- coding: utf-8 -*-
"""chatbot

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TCZxNMqM2IRWDz3-7NJj0zo_G57AjodX
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# from langchain_google_genai import ChatGoogleGenerativeAI
# from langchain_huggingface import HuggingFaceEmbeddings
# from langchain_text_splitters import RecursiveCharacterTextSplitter
# from langchain_chroma import Chroma
# from langchain_community.document_loaders import PyPDFLoader
# from langchain_core.prompts import ChatPromptTemplate
# from langchain_core.runnables import RunnablePassthrough
# from langchain_core.output_parsers import StrOutputParser
# import os
# import tempfile
# 
# 
# os.environ["GEMINI_API_KEY"] ="AIzaSyAr0oVllhtfgplb16y0But3h7aa9scdRKs"
# 
# DB_DIR = "/content/chroma_db"
# os.makedirs(DB_DIR, exist_ok=True)
# 
# llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.3)
# embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
# 
# st.set_page_config(page_title="Chatbot", page_icon="rocket")
# st.title("Chatbot")
# st.markdown("**Upload  → Create Database → Ask questions!**")
# 
# uploaded_files = st.file_uploader("Upload.pdf", type=["pdf"], accept_multiple_files=True)
# 
# if uploaded_files:
#     for uploaded_file in uploaded_files:
#         with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
#             tmp_file.write(uploaded_file.getvalue())
#             tmp_path = tmp_file.name
# 
#         final_path = f"/content/{uploaded_file.name}"
#         os.rename(tmp_path, final_path)
#     st.success("uploaded!")
# 
# if st.button("Create Database", type="primary"):
#     with st.spinner("Processing ..."):
#         docs = []
#         for f in os.listdir("/content"):
#             if f.endswith(".pdf"):
#                 docs.extend(PyPDFLoader(f"/content/{f}").load())
#         chunks = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(docs)
#         Chroma.from_documents(chunks, embeddings, collection_name="Chatbot", persist_directory=DB_DIR)
#         st.success(f"Database ready with {len(chunks)} chunks! Now ask!")
# 
# query = st.text_input("Ask about Sakthivel", placeholder="e.g. What is his phone number?")
# 
# if query:
#     with st.spinner("Searching..."):
#         try:
#             db = Chroma(collection_name="Chatbot", embedding_function=embeddings, persist_directory=DB_DIR)
#             retriever = db.as_retriever(search_kwargs={"k": 4})
#             chain = (
#                 {"context": retriever, "input": RunnablePassthrough()}
#                 | ChatPromptTemplate.from_template("Answer from ptf only. If not found, say 'Not in resume'.\nContext: {context}\nQuestion: {input}")
#                 | llm
#                 | StrOutputParser()
#             )
#             answer = chain.invoke(query)
#             st.balloons()
#             st.success(answer)
#         except Exception as e:
#             st.error("Create database first or check API key!")





